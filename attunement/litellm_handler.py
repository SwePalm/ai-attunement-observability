
from litellm import completion

from dotenv import load_dotenv
load_dotenv() # load settings from .env file

from attunement.config import LITELLM_MODEL_NAME


def get_text_from_litellm(prompt_string, model_name=LITELLM_MODEL_NAME): 

    """
    Calls the LiteLLM model with the provided prompt string and returns the generated text.
    
    Args:
        prompt_string (str): The fully formatted prompt to send to the model.
        
    Returns:
        str: The essay text generated by the model, or an error message.
    """   

    try:
        response = completion(
            #model="nebius/moonshotai/Kimi-K2-Instruct",
            # model="nebius/openai/gpt-oss-120b",
            model="nebius/Qwen/Qwen3-30B-A3B-Thinking-2507",
            messages=[
                {
                    "role": "user",
                    "content": prompt_string,
                }
            ],
            temperature=0.1,
        )

        return response.choices[0].message.content
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        raise Exception